# üìå AI Engineering

## üéØ Goal:
Gain hands-on experience in deploying, fine-tuning, and integrating AI models into applications.

### **1Ô∏è‚É£ AI Development Basics**

- [ ] **Running AI models locally** (Mistral, Ollama) - [Ollama Docs](https://ollama.ai/)
- [ ] **Using LLM APIs for development** (OpenAI, Replicate) - [Replicate API Docs](https://replicate.com/docs)
- [ ] **Fine-tuning vs. RAG** (Retrieval-Augmented Generation) - [LangChain RAG Guide](https://python.langchain.com/docs/use_cases/question_answering/)

---

### **2Ô∏è‚É£ AI Infrastructure & Scaling**

- [ ] **Self-hosted AI vs. Cloud AI (AWS, GCP)** - [AWS AI Services](https://aws.amazon.com/machine-learning/) | GCP AI Services
- [ ] **Optimizing AI for Performance (GPU vs. CPU)** - [NVIDIA AI Optimization](https://developer.nvidia.com/machine-learning)
- [ ] **AI Model Compression & Quantization** - TensorFlow Model Optimization

---

### **üéØ Hands-on Tasks**

- [ ] Deploy a self-hosted LLM chatbot
- [ ] Experiment with RAG using LangChain
- [ ] Integrate AI-powered recommendations into a web app
